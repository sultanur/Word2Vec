{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ca4713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "import googleapiclient.discovery\n",
    "from urllib.parse import parse_qs, urlparse\n",
    "import re\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9027740f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 20000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'print([ \\n    f\\'https://www.youtube.com/watch?v={t[\"snippet\"][\"resourceId\"][\"videoId\"]}&list={playlist_id}&t=0s\\'\\n    for t in playlist_items])'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract playlist id from url\n",
    "playlist_items = []\n",
    "url = 'https://www.youtube.com/playlist?list=UUupvZG-5ko_eiXAupbDfxWw'\n",
    "#https://www.youtube.com/playlist?list=PLlTLHnxSVuIzF88J3Ps_EB5UowGTgG97e  //url of FOX channel\n",
    "query = parse_qs(urlparse(url).query, keep_blank_values=True)\n",
    "playlist_id = query[\"list\"][0]\n",
    "\n",
    "#print(f'get all playlist items links from {playlist_id}')\n",
    "youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey = \"AIzaSyD_GXhNSThj_PSSXOv0QUfBbqYQV68jnMc\")\n",
    "\n",
    "request = youtube.playlistItems().list(\n",
    "    part = \"snippet\",\n",
    "    playlistId = playlist_id,\n",
    "    maxResults = 50\n",
    ")\n",
    "response = request.execute()\n",
    "\n",
    "while request is not None:\n",
    "    response = request.execute()\n",
    "    playlist_items += response[\"items\"]\n",
    "    request = youtube.playlistItems().list_next(request, response)\n",
    "\n",
    "print(f\"total: {len(playlist_items)}\")\n",
    "playlist = ([f'https://www.youtube.com/watch?v={t[\"snippet\"][\"resourceId\"][\"videoId\"]}&list={playlist_id}&t=0s'\n",
    "    for t in playlist_items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66faa672",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Expracting comments from each video\n",
    "def ScrapComment(url):\n",
    "    data = []\n",
    "    option = webdriver.FirefoxOptions()\n",
    "    option.add_argument(\"--headless\")\n",
    "    driver = webdriver.Firefox(executable_path=GeckoDriverManager().install(), options=option)\n",
    "    driver.get(url)\n",
    "    time.sleep(10)\n",
    "    prev_h = 0\n",
    "    while True:\n",
    "        height = driver.execute_script(\"\"\"\n",
    "                function getActualHeight() {\n",
    "                    return Math.max(\n",
    "                        Math.max(document.body.scrollHeight, document.documentElement.scrollHeight),\n",
    "                        Math.max(document.body.offsetHeight, document.documentElement.offsetHeight),\n",
    "                        Math.max(document.body.clientHeight, document.documentElement.clientHeight)\n",
    "                    );\n",
    "                }\n",
    "                return getActualHeight();\n",
    "            \"\"\")\n",
    "        driver.execute_script(f\"window.scrollTo({prev_h},{prev_h + 200})\")\n",
    "        time.sleep(5)\n",
    "        prev_h +=200  \n",
    "        if prev_h >= height:\n",
    "            break\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    #print(soup)\n",
    "    driver.quit()\n",
    "    title_text_div = soup.select_one(\"#container h1\")\n",
    "    title = title_text_div and title_text_div.text\n",
    "    print(title_text_div.text)\n",
    "    comment_div = soup.select(\"#content-text\")\n",
    "    #data.append(comment_div.text)       \n",
    "    comment_list = [x.text for x in comment_div]\n",
    "    print(comment_list)\n",
    "    df = pd.DataFrame(comment_list, columns = ['comments'])\n",
    "    df.to_csv(\"Comments_CNN.csv\", index=False,encoding='utf-8', mode='a', sep='-')\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    for url in playlist:\n",
    "        try:\n",
    "            ScrapComment(url)\n",
    "            print(url)\n",
    "        except:\n",
    "            print(f\"Couldn't open link{url}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "732d2b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2146814\n"
     ]
    }
   ],
   "source": [
    "#reading files and preprocessing \n",
    "string_comments_CNN = ''\n",
    "with open('Comments_CNN.csv','r') as csvfile:\n",
    "    read_Comments_CNN = csv.reader(csvfile, delimiter=',')\n",
    "    Comments_CNN = (row for row in read_Comments_CNN if row) # Filter out empty rows\n",
    "    for row in Comments_CNN:\n",
    "        string_comments_CNN += ' ' + row[0]\n",
    "res = len(string_comments_CNN.split())\n",
    "print(res)\n",
    "string_comments_CNN = string_comments_CNN.lower()  \n",
    "processed_comments_CNN  = re.sub('[^a-zA-Z]', ' ', string_comments_CNN  )\n",
    "processed_comments_CNN = re.sub(r'\\s+', ' ', processed_comments_CNN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a4e59ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022432\n"
     ]
    }
   ],
   "source": [
    "#reading files and preprocessing \n",
    "string_comments_FOX = ''\n",
    "with open('Comments_FOX.csv','r') as csvfile:\n",
    "    read_Comments_FOX = csv.reader(csvfile, delimiter=',')\n",
    "    Comments_FOX = (row for row in read_Comments_FOX if row) # Filter out empty rows\n",
    "    for row in Comments_FOX:\n",
    "        string_comments_FOX += ' ' + row[0]\n",
    "res = len(string_comments_FOX.split())\n",
    "print(res)\n",
    "string_comments_FOX = string_comments_FOX.lower()  \n",
    "processed_comments_FOX  = re.sub('[^a-zA-Z]', ' ', string_comments_FOX  )\n",
    "processed_comments_FOX = re.sub(r'\\s+', ' ', processed_comments_FOX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "01515b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the dataset\n",
    "all_sentences_FOX = nltk.sent_tokenize(processed_comments_FOX)\n",
    "all_words_FOX = [nltk.word_tokenize(sent) for sent in all_sentences_FOX]\n",
    "#Removing Stop words\n",
    "from nltk.corpus import stopwords\n",
    "for i in range(len(all_words_FOX)):\n",
    "    all_words_FOX[i] = [w for w in all_words_FOX[i] if w not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "37098f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the dataset\n",
    "all_sentences_CNN = nltk.sent_tokenize(processed_comments_CNN)\n",
    "all_words_CNN = [nltk.word_tokenize(sent) for sent in all_sentences_CNN]\n",
    "#Removing Stop words\n",
    "from nltk.corpus import stopwords\n",
    "for i in range(len(all_words_CNN)):\n",
    "    all_words_CNN[i] = [w for w in all_words_CNN[i] if w not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "50fbc6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "word2vec_FOX = Word2Vec(all_words_FOX, vector_size=100)\n",
    "#To see the dictionary of unique words that exist at least twice in the corpus, execute the following script:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a5c20f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13235"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2vec_FOX.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "91644095",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_CNN = Word2Vec(all_words_CNN, vector_size=20)\n",
    "word2vec_FOX = Word2Vec(all_words_FOX, vector_size=20)\n",
    "#To see the dictionary of unique words that exist at least twice in the corpus, execute the following script:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bd894cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13716\n",
      "13235\n"
     ]
    }
   ],
   "source": [
    "print(len(word2vec_CNN.wv))\n",
    "print(len(word2vec_FOX.wv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ac71671c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04930339,  0.01104132, -0.03159291,  0.03037217,  0.04990425,\n",
       "       -0.00478909, -0.03149902, -0.04662199, -0.03137704, -0.0364631 ,\n",
       "       -0.02982504,  0.01044771,  0.03290243, -0.02569067,  0.02477772,\n",
       "       -0.01271182, -0.00623436, -0.03236331,  0.01911088, -0.00182292],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = word2vec_CNN.wv['artificial']\n",
    "cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d81dfcde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01863745, -0.01342919,  0.00673482,  0.045663  ,  0.03492564,\n",
       "       -0.00602473,  0.00449594,  0.04391222, -0.03773825, -0.02931326,\n",
       "        0.00666834,  0.01171998,  0.00476553,  0.001056  , -0.01888318,\n",
       "        0.01707846, -0.02734752,  0.02329854,  0.01004614,  0.00626465],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fox = word2vec_FOX.wv['artificial']\n",
    "fox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e8896a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('election', 0.7713823914527893),\n",
       " ('facade', 0.7402766942977905),\n",
       " ('tops', 0.7384052872657776),\n",
       " ('germs', 0.7312322854995728),\n",
       " ('cnn', 0.7307876944541931),\n",
       " ('palestine', 0.7265436053276062),\n",
       " ('donald', 0.7211888432502747),\n",
       " ('bunker', 0.7171562314033508),\n",
       " ('bad', 0.7009894251823425),\n",
       " ('said', 0.6919741630554199)]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_words_CNN = word2vec_CNN.wv.most_similar('trump')\n",
    "sim_words_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "dd2bb75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lemon', 0.8659694194793701),\n",
       " ('man', 0.8561779856681824),\n",
       " ('go', 0.8428375720977783),\n",
       " ('mansplain', 0.8368316292762756),\n",
       " ('tucker', 0.8309161067008972),\n",
       " ('cnn', 0.8297308683395386),\n",
       " ('name', 0.8232432007789612),\n",
       " ('love', 0.8205192685127258),\n",
       " ('call', 0.8143322467803955),\n",
       " ('cuomo', 0.8048670887947083)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_words_FOX = word2vec_FOX.wv.most_similar('trump')\n",
    "sim_words_FOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8b482e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tents', 0.7960835695266724),\n",
       " ('seven', 0.7621609568595886),\n",
       " ('economic', 0.7542464733123779),\n",
       " ('factory', 0.7425649166107178),\n",
       " ('guards', 0.7204541563987732),\n",
       " ('trumpist', 0.6947533488273621),\n",
       " ('une', 0.693173885345459),\n",
       " ('iowa', 0.6875284314155579),\n",
       " ('ultimately', 0.6800395846366882),\n",
       " ('dilemma', 0.6736147999763489)]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_words_CNN = word2vec_CNN.wv.most_similar('pelosi')\n",
    "sim_words_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c063a5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('swallowwell', 0.8192545175552368),\n",
       " ('suggests', 0.7264533638954163),\n",
       " ('competing', 0.7263786196708679),\n",
       " ('demonstrated', 0.7124740481376648),\n",
       " ('aircraft', 0.6990479826927185),\n",
       " ('unemployment', 0.6975025534629822),\n",
       " ('duty', 0.694275975227356),\n",
       " ('marxist', 0.6888642907142639),\n",
       " ('falls', 0.68801349401474),\n",
       " ('postal', 0.6826593279838562)]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_words_FOX = word2vec_FOX.wv.most_similar('pelosi')\n",
    "sim_words_FOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ae927399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('recitation', 0.7789483070373535),\n",
       " ('wilt', 0.7082784175872803),\n",
       " ('non', 0.6988403797149658),\n",
       " ('bigfoot', 0.6824818849563599),\n",
       " ('unpack', 0.680051863193512),\n",
       " ('minimal', 0.6716213822364807),\n",
       " ('mismanagement', 0.6679967045783997),\n",
       " ('raises', 0.662876546382904),\n",
       " ('informant', 0.6627371907234192),\n",
       " ('hardly', 0.6571428775787354)]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_words_CNN = word2vec_CNN.wv.most_similar('obama')\n",
    "sim_words_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1ebc7a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gagging', 0.8045994639396667),\n",
       " ('labeled', 0.743431806564331),\n",
       " ('stooge', 0.7418817281723022),\n",
       " ('talent', 0.7269473075866699),\n",
       " ('throws', 0.7221507430076599),\n",
       " ('somewhere', 0.7040992379188538),\n",
       " ('mar', 0.689964234828949),\n",
       " ('payroll', 0.6864908933639526),\n",
       " ('lil', 0.6836626529693604),\n",
       " ('depp', 0.672944962978363)]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_words_FOX = word2vec_FOX.wv.most_similar('obama')\n",
    "sim_words_FOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ae8ecf82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('club', 0.785166323184967),\n",
       " ('dan', 0.7063941359519958),\n",
       " ('fabrications', 0.7021914720535278),\n",
       " ('yea', 0.7013432383537292),\n",
       " ('stability', 0.6981852054595947),\n",
       " ('auditorium', 0.68854159116745),\n",
       " ('dominican', 0.687610387802124),\n",
       " ('spouting', 0.6831396222114563),\n",
       " ('wildest', 0.6821116209030151),\n",
       " ('commenting', 0.6819189190864563)]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_words_CNN = word2vec_CNN.wv.most_similar('putin')\n",
    "sim_words_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "08b316d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('greatness', 0.7966035008430481),\n",
       " ('conform', 0.7863489985466003),\n",
       " ('lovers', 0.6898960471153259),\n",
       " ('haply', 0.6860864758491516),\n",
       " ('mundane', 0.6851803660392761),\n",
       " ('pulled', 0.6780452132225037),\n",
       " ('sesame', 0.6763952374458313),\n",
       " ('overlords', 0.6688169836997986),\n",
       " ('beef', 0.6658833622932434),\n",
       " ('aptitude', 0.6591931581497192)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_words_FOX = word2vec_FOX.wv.most_similar('putin')\n",
    "sim_words_FOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "960cf4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('abdul', 0.7324193716049194),\n",
       " ('excessive', 0.7194420695304871),\n",
       " ('play', 0.7170838713645935),\n",
       " ('purposes', 0.7144263386726379),\n",
       " ('h', 0.6953667998313904),\n",
       " ('grey', 0.6939713358879089),\n",
       " ('low', 0.686253011226654),\n",
       " ('mother', 0.678110659122467),\n",
       " ('meaning', 0.6688559651374817),\n",
       " ('katrina', 0.6642398238182068)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_words_CNN = word2vec_CNN.wv.most_similar('democrat')\n",
    "sim_words_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "302251a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('broker', 0.7858495116233826),\n",
       " ('locked', 0.7406540513038635),\n",
       " ('bail', 0.6903342008590698),\n",
       " ('incentives', 0.6900686621665955),\n",
       " ('rocks', 0.6848512291908264),\n",
       " ('appointing', 0.6844769716262817),\n",
       " ('transgenders', 0.6817702651023865),\n",
       " ('posse', 0.676032304763794),\n",
       " ('infectious', 0.6654408574104309),\n",
       " ('troublesome', 0.6605979800224304)]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_words_FOX = word2vec_FOX.wv.most_similar('democrat')\n",
    "sim_words_FOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7317f538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
